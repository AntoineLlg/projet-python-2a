{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2141b1f3",
   "metadata": {},
   "source": [
    "# Analyse de commentaires YouTube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154b74b0",
   "metadata": {},
   "source": [
    "Projet Python de deuxième année à l'ENSAE Paris.\n",
    "\n",
    " Louisa Camadini, Antoine Lelong, Yseult Masson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5b67b5",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4db40c1",
   "metadata": {},
   "source": [
    "Les commentaires postés sous les vidéos YouTube sont une source d'information, complémentaire avec les \"likes\", pour les créateurs de contenu. Ils permettent au vidéaste de déterminer si son travail a plu ou non à son audience. Cependant, les Youtubeurs n'ont pas nécessairement le temps de tous les lire. Il nous a donc semblé intéressant d'analyser ces commentaires informatiquement, plutôt que de les traiter un à un.\n",
    "\n",
    "Pour ce projet, nous nous sommes penchés sur la chaîne YouTube DirtyBiology, qui fait de la vulgarisation scientifique. Notre choix a été motivé par le fait que les commentaires sous ces vidéos sont à la fois nombreux (car la chaîne est relativement connue), en phrases (étant donné l'audience cible) et sans trop de fautes d'ortographes. Cela nous a permis d'avoir des données exploitables pour l'analyse que nous voulions en faire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafa18ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3de2a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des modules utiles\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40d1160",
   "metadata": {},
   "source": [
    "# 1 - Webscraping, création et nettoyage de la base de données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29daa6e4",
   "metadata": {},
   "source": [
    "## 1.1 - Webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc18905b",
   "metadata": {},
   "source": [
    "Dans un premier temps, nous avons utilisé [l'API YouTube Data](https://developers.google.com/youtube/v3), qui nous permet de récupérer les 100 commentaires les plus \"pertinents\" d'une vidéo, sur jusqu'à 20 vidéos différentes, constituant une base de données de 2000 commentaires, ainsi que quelques données supplémentaires, comme le nombre de likes, le nom d'utilisateur...  \n",
    "Le script`scraper.py` va chercher ces données et les stocke dans le fichier `comments.csv`.  \n",
    "Les API Google fonctionnent avec des clés d'identification confidentielles, qui n'apparaissent par conséquent pas dans le dépot github. Pour faire fonctionner le script correctement, il faut créer un fichier s'apppelant `.env` et y placer la ligne suivante :  \n",
    "`APIKEY=\"identifiant_de_la_clé\"`  \n",
    "Dans tous les cas, le fichier `comments.csv` que nous avons constitué est, lui, disponible dans le dépot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90171e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python scraper.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bfc977",
   "metadata": {},
   "source": [
    "## 1.2 - Nettoyage de la base de données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9031337",
   "metadata": {},
   "source": [
    "Le script cleaning prépare les commentaires pour les autres parties, en retirant les majuscules, sauts de lignes... en créant une nouvelle variable `textClean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931c146c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python cleaning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb153d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"comments.csv\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dbc5f3",
   "metadata": {},
   "source": [
    "# 2 - Analyse des commentaires\n",
    "## 2.1 - Analyse exploratoire quantitative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7886ccfa",
   "metadata": {},
   "source": [
    "Par simplicité, on remplace les identifiants des vidéos par des numéros dans l'ordre de publication (1 pour la plus ancienne, 20 pour la dernière)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3842f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = {data.videoId.unique()[i] : 20- i for i in range(len(data.videoId.unique()))}\n",
    "data['videoId']=data['videoId'].replace(to_replace=dico)\n",
    "data.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ea1af2",
   "metadata": {},
   "source": [
    "Certaines données caractérisent la vidéo et non le commentaire, on les récupère dans une autre DataFrame. Elles sont égales sur une vidéo, donc égales à leur max sur ces groupes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9b3391",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_video = data.groupby('videoId')[['viewCount', 'commentCount', 'videoLikeCount','videoDate']].max()\n",
    "info_video['likePerView'] = info_video['videoLikeCount'] / info_video['viewCount']\n",
    "info_video['Engagement'] = info_video['commentCount'] / info_video['viewCount']\n",
    "info_video.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e06160b",
   "metadata": {},
   "source": [
    "On crée une variable correspondant au nombre de mois entre la publication de la vidéo et celle de la dernière vidéo de la base de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df94afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_mois = lambda date : 25 - (int(date[5:7]) + 12 * int(date[3]))\n",
    "info_video['ancienneté'] = info_video.videoDate.apply(nbr_mois)\n",
    "info_video.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bb5dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "info_video.plot(y='likePerView', ax=axs[0][0], color='r')\n",
    "info_video.plot(y='Engagement', ax=axs[0][0], color='b')\n",
    "axs[0][0].axis([0,20,0,1])\n",
    "axs[0][0].set_title(\"Part d'engagement du public\")\n",
    "\n",
    "info_video.plot(y='likePerView', ax=axs[1][0], color='r')\n",
    "info_video.plot(y='Engagement', ax=axs[1][0], color='b')\n",
    "axs[1][0].set_title(\"Comparaison des proportions de like et commentaires\")\n",
    "\n",
    "info_video.plot(y='Engagement', ax=axs[0][1], color='b')\n",
    "axs[0][1].set_title(\"Variation de l'engagement par commentaires\")\n",
    "\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = linregress(x=info_video.ancienneté, y=info_video.Engagement)\n",
    "\n",
    "info_video.plot.scatter(x='ancienneté', y='Engagement', ax=axs[1][1])\n",
    "axs[1][1].plot(info_video.ancienneté, slope * info_video.ancienneté + intercept, color='c')\n",
    "axs[1][1].set_title(\"Regression linéaire de l'engagement en commentaires sur l'ancienneté\")\n",
    "plt.text(x=0.5, y=0.006, s=f\"Slope = {slope:.2e}\\nR-squared = {r_value ** 2:.2f} \\nP-value = {p_value:.3f}\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06544285",
   "metadata": {},
   "source": [
    "Comme on peut le voir, la part de viewers qui likent et commentent reste stable autour de 9% et 0.4% respectivement, soit une minorité de la totalité des viewers.  \n",
    "On remarque une tendance d'augmentation de la proportion de viewers qui commentent avec l'ancienneté de la vidéo, ce qui suggère que les personnes qui regardent une vidéo tard par rapport à sa sortie ont plus tendance à la commenter. L'interprétation de la régression linéaire donne que pour chaque mois qui passe, cette proportion augmente en moyenne de 0.001 (pour rappel, elle varie aux alentours de 0.004 sur les observations). La P-valeur à 0.006 montre que le coefficient de la courbe est significatif au seuil 1%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5902d9",
   "metadata": {},
   "source": [
    "## 2.2 - Thèmes majoritairement abordés dans les commentaires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1771a2",
   "metadata": {},
   "source": [
    "Imports nécessaires pour cette partie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178034b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b11cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('genesis')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d3a5b6",
   "metadata": {},
   "source": [
    "### A - Tokenisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cb71df",
   "metadata": {},
   "source": [
    "On va s'intéresser ici à la colonne `textClean` qui a été nettoyée au préalable. Chaque ligne du dataframe représente un commentaire. L'ensemble de ces lignes, c'est-à-dire tous les commentaires, correspondent donc à notre texte d'étude. Il s'agit tout d'abord de décomposer le texte en unités lexicales, afin de pouvoir analyser les impressions laissées en commentaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0730b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \" \".join(data['textClean'])\n",
    "\n",
    "words = nltk.word_tokenize(content, language='french')\n",
    "#words[200:250]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86d92c8",
   "metadata": {},
   "source": [
    "La texte a bien été décomposé en 'tokens', mais ce ne sont pas tous des mots : certains peuvent être des signes de ponctuation, des smileys... \n",
    "La méthode `isalpha()` renvoie \"True\" si tous les caractères de la chaîne sont des alphabets, on l'utilise pour ne garder que les 'tokens' qui sont des mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf847b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word for word in words if word.isalpha()]\n",
    "#words[200:250]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd9979b",
   "metadata": {},
   "source": [
    "Maintenant, certains mots comme les déterminants ou pronoms, sont répétitifs et inutiles à l'analyse du texte. On supprime donc ce qu'on appelle les 'stopwords' :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf78ef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('french'))\n",
    "\n",
    "words = [w for w in words if not w in stop_words]\n",
    "print(words[200:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1106ff7a",
   "metadata": {},
   "source": [
    "### B - Création de WordClouds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d12634",
   "metadata": {},
   "source": [
    "Ils permettent de synthétiser les mots et expressions qui reviennent le plus couramment dans les commentaires.\n",
    "Les images produites pour cette partie sont disponibles dans l'onglet [graphes](https://github.com/taucmar/projet-python-2a/tree/main/graphs) de notre dépôt GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c2f329",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7965a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(text)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96e99b4",
   "metadata": {},
   "source": [
    "On a ici généré un premier nuage de points classique, composé de 100 mots qui semblent positifs dès le premier coup d'œil :  travail, merci, incroyable , bravo, intéressant, qualité...  \n",
    "On customise ce nuage de mots en l'intégrant au logo YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4faf0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array(Image.open(\"mask.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0868fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(background_color=\"white\", max_words=90, mask=mask,\n",
    "               stopwords=stop_words, contour_width=3, contour_color='firebrick')\n",
    "\n",
    "wc.generate(text)\n",
    "\n",
    "wc.to_file(\"./graphs/logo_youtube.png\")\n",
    "\n",
    "plt.figure(figsize=[10,8])\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bd23c6",
   "metadata": {},
   "source": [
    "Mieux encore, on peut utiliser le logo de DirtyBiology, en retravaillant des [images](https://www.pinterest.fr/pin/148689225175699166/) trouvées sur Internet. L'image qui suit a été produite de la même manière."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a1be86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"./graphs/logo_dirty_bio.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e8632f",
   "metadata": {},
   "source": [
    "## 2.3 - Polarisation des commentaires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1084f35b",
   "metadata": {},
   "source": [
    "### A - Calcul de polarités"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684edc78",
   "metadata": {},
   "source": [
    "Le module TextBlob est un module python de NLP utilisé pour l'analyse de sentiments et qui permet, entre autres, de calculer la polarité d'un texte. Celle-ci est un nombre entre -1 et 1, qui détermine le degré de satisfaction ou d'insatisfaction qui se dégage du texte. Plus la polaritée est proche de 1, plus le texte dégage un sentiment positif, et vice-versa.\n",
    "\n",
    "Nous avons calculé la polarité de chaque commentaire de deux façons. Les fonctions permettant de faire ces calculs se trouvent dans le fichier `polaritation_utiles.py`. Nous avons d'une part appliqué directement la fonction du module TextBlob qui nous intéresse au commentaire. D'autre part, nous avons découpé chaque commentaire en phrases, avant d'appliquer à chacune de celles-ci la fonction qui renvoie leur polarisation, puis d'en faire la moyenne sur toutes les phrases du commentaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9f973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polarisation_utiles as pu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d6804f",
   "metadata": {},
   "source": [
    "Nous avons ensuite ajouté 2 nouvelles colonnes à la base de données:\n",
    "\n",
    "   - Polarity : polarité de chaque commentaire, calculée sur le commentaire entier directement\n",
    "    \n",
    "   - sentencesPolarity : polarité de chaque commentaire, calculée en prenant la moyenne des polarités sur chaque phrase que comporte le commentaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cf8248",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Polarity\"] = data.loc[:, ['textClean']].apply(pu.blober)\n",
    "data[\"sentencesPolarity\"] = data.loc[:, ['textClean']].apply(pu.polarisation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f662d18b",
   "metadata": {},
   "source": [
    "Pour la clarté des graphiques nous avons créé une colonne correspondant aux numéros des vidéos indiqués dans les titres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1829d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DBY'] = data.loc[:, ['videoTitle']].apply(np.vectorize(lambda string : string[-7:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd90987",
   "metadata": {},
   "source": [
    "### B - Analyse des polarités"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5ee34b",
   "metadata": {},
   "source": [
    "**Analyse d'une vidéo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac3fb3c",
   "metadata": {},
   "source": [
    "Dans un premier temps, on s'intéresse à la répartition des polarités pour une vidéo, ici la vidéo *Comment ces champis nous ont façonnés - DBY #76*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235d16e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DBY76 = data.loc[data['DBY'] == \"DBY #76\", ['Polarity', 'sentencesPolarity']]\n",
    "DBY76.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc694dff",
   "metadata": {},
   "source": [
    "On voit que pour les deux types de polarité, il y a très peu de valeurs négatives. Cela signifie que les commentaires de cette vidéo sont pour la plupart perçus comme positifs.\n",
    "Les écarts type sont de 0.29 et 0.26, ce qui est assez élevé pour des valeurs de polarités allant entre -0.2 (-0.1 pour \"sentencesPolarity\") et 1. Ainsi, les commentaires de cette vidéo dégagent plusieurs degrés de satisfaction, allant de neutre à très satisfait. La moitié d'entre eux sont relativement satisfaits, et ont une polarité se trouvant entre 0.15 et 0.50 (0.12 et 0.45 pour sentencesPolarity).\n",
    "\n",
    "Cela se perçoit bien sur les histogrammes ci-dessous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036b0d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "DBY76['Polarity'].plot.density(ax = axs[0])\n",
    "DBY76['Polarity'].plot.hist(bins=20, density=True, ax = axs[0])\n",
    "\n",
    "axs[0].set_xlabel(\"Polarité calculée sur le commentaire entier\")\n",
    "axs[0].set_ylabel(\"Nombre de commentaires (renormalisé)\")\n",
    "axs[0].set_title(\"Répartition des polarités des commentaires sous la vidéo DBY #76\")\n",
    "\n",
    "DBY76['sentencesPolarity'].plot.density(ax=axs[1])\n",
    "DBY76['sentencesPolarity'].plot.hist(bins=20, density=True, ax=axs[1])\n",
    "\n",
    "axs[1].set_xlabel(\"Polarité calculée sur les phrases du commentaire prises une à une\")\n",
    "axs[1].set_ylabel(\"Nombre de commentaires (renormalisé)\")\n",
    "axs[1].set_title(\"Répartition des polarités des commentaires sous la vidéo DBY #76\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca79733",
   "metadata": {},
   "source": [
    "**Comparaison des vidéos entre elles**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab013b2e",
   "metadata": {},
   "source": [
    "Nous avons ensuite fait la moyenne des polarités sur les 100 commentaires de chaque vidéo, ce qui nous permet de comparer les vidéos entre elles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad93319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapol = data.groupby(['DBY']).mean().sort_values('Polarity', ascending = False)\n",
    "datapol.loc[:, ['videoLikeCount', 'Polarity', 'sentencesPolarity']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef48c7e8",
   "metadata": {},
   "source": [
    "Nous avons cherché à savoir si les résultats de polarisation restaient cohérents entre les deux méthodes utilisées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe8e8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapol.loc[:,['Polarity', 'sentencesPolarity']].plot(kind='barh', figsize=(11, 7), color=['lightblue', 'green'], title='Comparaison entre polarité sur les commentaires entiers et polarité sur les phrases des commentaires', xlabel='Episode de DirtyBiology')\n",
    "plt.legend(labels=['Polarité : Commentaires entiers', 'Polarité : Phrases prises une à une'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e47041f",
   "metadata": {},
   "source": [
    "L'ordre des vidéos change un peu selon la définition que l'on utilise pour la polarité, mais les deux définitions semblent tout de même corrélées (globalement, la polarité prise sur chaque phrase augmente avec celle prise sur le commentaire entier).\n",
    "\n",
    "Dans la suite, on garde la polarité sur le commentaire entier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa79561f",
   "metadata": {},
   "source": [
    "**Relation entre le nombre de likes d'un commentaire et sa polarité**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088a5302",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.sort_values(\"Polarity\").set_index(\"Polarity\")[\"commentLikeCount\"]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 10))\n",
    "\n",
    "for i, ax in enumerate(np.array(axs).flatten()):\n",
    "    plot_data = data2.iloc[500 * i:500 * (i + 1)]\n",
    "    plot_data.plot.density(ax=ax)\n",
    "    plot_data.plot.hist(bins=[0] + [200 + 50 * i for i in range(100)], density=True, ax=ax)\n",
    "    ax.set_xlabel(\"Nombre de likes reçus par le commentaire\")\n",
    "    ax.set_ylabel(\"Nombre de commentaires (renormalisé)\")\n",
    "    ax.set_title(\"Répartition du nombre de likes reçus par les commentaires renvoyant un sentiment \" + [\"négatif ou neutre\", \"légèrement positif\", \"positif\", \"très positif\"][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489c3075",
   "metadata": {},
   "source": [
    "Sur chacun des graphiques, la première barre représente les commentaires ayant reçu moins de 200 likes. En effet, il y a énormément de commentaires qui reçoivent 0 likes, et la barre associée dans l'histogramme écrase les autres si on ne réunit pas plus de valeurs autour de 0.  \n",
    "Il semble que les commentaires les moins positifs (ce qui ont la polarité la plus faible) sont ceux qui ont le plus de chance d'avoir du succès. Cela pourrait être dû au fait que les commentaires émettant un avis, qui sont ceux qui reçoivent le plus de likes, sont plutôt neutres, contrairement à ceux qui indiquent que la vidéo a plu, qui dégagent un sentiment positif, mais ne suscite pas particulièrement d'être likés par d'autres viewers. L'analyse en wordcloud suggère que ce dernier genre de commentaires est très présent dans notre corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2d1b35",
   "metadata": {},
   "source": [
    "**Pertinence de la polarité**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4051d9bf",
   "metadata": {},
   "source": [
    "La polarité devrait être un témoin du succès qu'a eu une vidéo. On cherche à présent à la comparer à un autre marqueur de ce succès, à savoir le ratio de likes qu'a reçu une vidéo par rapport à son nombre de vues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3869ec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapol['likeRatio'] = datapol['videoLikeCount'] / datapol['viewCount']\n",
    "datapol.plot(kind='scatter', \n",
    "             x='Polarity', \n",
    "             y='likeRatio', \n",
    "             figsize=(6, 5), \n",
    "             marker='d', \n",
    "             xlabel='Polarité', \n",
    "             ylabel='Ratio de \\\"likes\\\" par rapport au nombre de vues', \n",
    "             title='Corrélation entre la polarité et le nombre de \\\"likes\\\" d\\'une vidéo')\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = linregress(x=datapol.Polarity, y=datapol.likeRatio)\n",
    "\n",
    "plt.plot(datapol.Polarity, slope * datapol.Polarity + intercept, color='c')\n",
    "plt.text(x=0.24, y=0.11, s=f\"Slope = {slope:.2e}\\nR-squared = {r_value ** 2:.2f} \\nP-value = {p_value:.3f}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917e78ae",
   "metadata": {},
   "source": [
    "Il semble ne pas y avoir de corrélation entre ces deux marqueurs, ce que confirme la regression linéaire précédente : le coefficient de la droite de regression a une P-valeur de 0.84, donc il n'est pas significatif.  \n",
    "Cela peut être dû au fait que la polarisation ne soit pas très précise, ou que les personnes qui commentent les vidéos n'aient pas le même profil que ceux qui se contentent de liker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0b10f9",
   "metadata": {},
   "source": [
    "## 2.4 - Analyse en composantes principales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bf239f",
   "metadata": {},
   "source": [
    "Dans cette partie, nous utilisons la bibliothèque [Sentence Transformer](https://github.com/UKPLab/sentence-transformers) pour transformer les phrases en vecteurs réels. Cela nous permet ensuite de faire une ACP, pour visualiser les différences entre les commentaires, et étudier les plus extrêmes, puisque l'ACP conserve un maximum de variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4fec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599bb22a",
   "metadata": {},
   "source": [
    "### A - Préparation de l'encoding\n",
    "1. On récupère les commentaires\n",
    "2. On isole le texte du reste de la base de données\n",
    "3. Dans la liste font, on fait correspondre à chaque indice de commentaire le numéro de la vidéo associée (pour faire des catégories dans l'ACP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3e3bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = SentenceTransformer(\"xlm-r-bert-base-nli-stsb-mean-tokens\")\n",
    "\n",
    "comments = data[['textClean', 'DBY']]\n",
    "\n",
    "text = comments[\"textClean\"].values.tolist()\n",
    "\n",
    "dico_font_video = {}\n",
    "\n",
    "for i, videoid in enumerate(comments.videoId.unique()):\n",
    "    dico_font_video[videoid] = i\n",
    "\n",
    "font = [dico_font_video[videoid] for videoid in comments.videoId]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ae9c6a",
   "metadata": {},
   "source": [
    "### B -  Encoding et ACP\n",
    "\n",
    "On peut ensuite encoder le texte, ce qui les transforme en vecteurs de $\\mathbb{R}^{768}$, qu'on projette après dans $\\mathbb{R}^{2}$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144687dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = st.encode(text)\n",
    "pca = PCA(2).fit_transform(embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dee0cf",
   "metadata": {},
   "source": [
    "### C - Clustering\n",
    "Pour une première visualisation, on réunit les commentaires par clusters (dans  $\\mathbb{R}^{768}$), et on utilise ces catégories lorsqu'on affiche sur l'ACP dans $\\mathbb{R}^{2}$. On récupère aussi les commentaires les plus proches des centroïdes afin d'avoir des commentaires \"représentants\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93de0654",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(5, n_init=80, max_iter=2000).fit(embs)\n",
    "\n",
    "center_indices = [\n",
    "    int(np.argmin([np.sum((x-centroid)**2) for x in embs]))\n",
    "    for centroid in kmeans.cluster_centers_]\n",
    "\n",
    "commentaires_representants = [comments.textClean[i] for i in center_indices]\n",
    "representants = ''\n",
    "for i, comment in enumerate(commentaires_representants):\n",
    "    representants += f'{i}:{comment} \\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899578f5",
   "metadata": {},
   "source": [
    "En préparation de l'affichage de cette partie et de la suivante, on stocke toutes les informations constituées jusque là dans une DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aa6265",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.array([pca[:, 0], pca[:, 1], font, kmeans.labels_]).transpose(),\n",
    "                    columns=['x', 'y', 'video#', 'label'])\n",
    "data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68617435",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.scatterplot(data=data,\n",
    "                x='x',\n",
    "                y='y',\n",
    "                hue='label',\n",
    "                style='label',\n",
    "                s=30,\n",
    "                hue_norm=(0,6),\n",
    "                alpha=.8,\n",
    "                palette='hsv',\n",
    "                legend='full')\n",
    "\n",
    "# Mise en avant des centroides\n",
    "sns.scatterplot(x=[pca[i, 0] for i in center_indices], \n",
    "                y=[pca[i, 1] for i in center_indices],\n",
    "                style=[i for i in range(len(center_indices))],\n",
    "                s=100,\n",
    "                legend=False)\n",
    "plt.title(\"ACP des commentaires + clustering\")\n",
    "plt.show()\n",
    "print(representants) #la liste des représentants a été faite avant le mélange de la dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dffcca8",
   "metadata": {},
   "source": [
    "Les commentaires centroides sont tous positifs, ce qui suggère que ce qui éloigne les plus les différents clusters les uns des autres ne résident pas dans la positivité ou négativité du commentaire ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ade6b2e",
   "metadata": {},
   "source": [
    "### D - Affichage par vidéo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cbee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.scatterplot(data=data,\n",
    "                x='x',\n",
    "                y='y',\n",
    "                hue='video#',\n",
    "                hue_norm=(0, 23),\n",
    "                s=50,\n",
    "                palette='hsv',\n",
    "                alpha=.5,\n",
    "                legend='full')\n",
    "plt.title(\"ACP des commentaires par video\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7dd0ce",
   "metadata": {},
   "source": [
    "Les commentaires de chaque vidéo ne semblent pas former de cluster particuliers dans l'ACP, on peut donc en déduire qu'aucune vidéo n'a suggéré de réaction particulièrement différente des autres, ou bien si des clusters sont cachés dans les dimensions perdues de la projections, c'est qu'ils ont des variances plus faibles que les différences observées dans l'ACP.  \n",
    "Pour vérfier encore ces similarités, on affiche simultannément l'ACP pour chaque nuage de point plutôt que de les superposer.\n",
    "Afin de pouvoir les comparer visuellement facilement, on entoure les nuages de points par l'enveloppe convexe du nuage total :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e313084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "hull = ConvexHull(pca)\n",
    "\n",
    "fig, axs = plt.subplots(4, 5, figsize=(14, 10))\n",
    "for i, ax in enumerate(np.array(axs).flatten()):\n",
    "    sns.scatterplot(x=[pca[j, 0] for j in range(len(font)) if font[j] == i],\n",
    "                    y=[pca[j, 1] for j in range(len(font)) if font[j] == i],\n",
    "                    s=50,\n",
    "                    ax=ax,\n",
    "                    alpha=0.4)\n",
    "    for simplex in hull.simplices:\n",
    "            ax.plot(pca[simplex, 0], pca[simplex, 1], 'c')\n",
    "    ax.set_title(f'Video {i+1}', fontsize=10)\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ef5d3e",
   "metadata": {},
   "source": [
    "Les nuages de points semblent se déplacer de gacuche à droite principalement, mais les variations ne sont pas énormes. Concrètement, les vidéos suscitent des réations similaires.  \n",
    "### E - À la frontière de l'ACP\n",
    "Les axes de l'ACP ne sont pas porteurs d'un sens clairement identifiable étant donnée la nature de la transformation des commentaires en vecteurs. On peut essayer de leur donner un sens en regardant les valeurs extrêmes de l'ACP et determiner ce qui éloigne les commentaire les plus éloignés d'un point de vue sémantique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a99c4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "for simplex in hull.simplices:\n",
    "    plt.plot(pca[simplex, 0], pca[simplex, 1], 'c')\n",
    "bound = np.array([pca[i] for i in hull.vertices])\n",
    "plt.scatter(x=bound[:, 0], y=bound[:, 1], color='r')\n",
    "for name, vect in zip(range(len(bound)), bound):\n",
    "    plt.annotate(name+1, vect)\n",
    "\n",
    "plt.title(\"Frontière de l'enveloppe convexe\")\n",
    "plt.show()\n",
    "print(*[f'{i+1} : ' + text[ind]+'\\n' for i, ind in enumerate(hull.vertices)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1af9f85",
   "metadata": {},
   "source": [
    "On remarque tout de suite que les commentaires de la région en haut à gauche (1, 2, 12, 13 et 14) partagent tous le même mot : \"merci\" et saluent la qualité et l'intérêt qu'ils ont pour la vidéo ('passionnant', 'enrichissant', 'intéressant', 'beau travail', 'travail de qualité'). Les commentaires du bas sont également élogieux. Tandis que les commentaires de la région opposée intègrent du langage fleuri (6: 'bordel', 8: 'merde') et sont moins élogieux, le commentaire le plus a droite semblant venir d'un professeur voulant se renseigner.  \n",
    "On peut donc supposer que plus on se déplace vers la partie gauche de l'espace, plus les commentaires sont élogieux, et les remerciements nombreux.\n",
    "\n",
    "On va essayer de vérifier cette interprétation.\n",
    "On isole les commentaires comprenant des remerciements :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069d7407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_remerciement(string):\n",
    "    return ('merci' in string) or ('thank' in string) or ('thx' in string)\n",
    "data = data.sort_index() # On remet les commentaire dans l'ordre de leurs indices\n",
    "remerciements =  data.iloc[[i for i in range(len(data)) if find_remerciement(text[i])]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165ae257",
   "metadata": {},
   "source": [
    "On regarde l'espace qu'ils occupent dans l'ACP :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9715a158",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_remerciements = np.array(remerciements[['x','y']])\n",
    "hull_remerciements = ConvexHull(pca_remerciements)\n",
    "\n",
    "sns.scatterplot(data=remerciements,\n",
    "                x='x',\n",
    "                y='y',\n",
    "                s=200,\n",
    "                alpha=.4,\n",
    "                legend='full')\n",
    "for simplex in hull.simplices:\n",
    "    plt.plot(pca[simplex, 0], pca[simplex, 1], 'c')\n",
    "for simplex in hull_remerciements.simplices:\n",
    "    plt.plot(pca_remerciements[simplex, 0], pca_remerciements[simplex, 1], 'r')\n",
    "plt.title(\"Commentaires de remerciement\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9282859",
   "metadata": {},
   "source": [
    "Finalement, les remerciements occupent quasiment tout l'espace de commentaires, donc l'interprétation précédente ne tient pas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
