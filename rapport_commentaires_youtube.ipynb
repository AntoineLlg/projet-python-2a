{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c3e5805",
   "metadata": {},
   "source": [
    "# Analyse de commentaires YouTube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056b8786",
   "metadata": {},
   "source": [
    "Projet Python de deuxième année à l'ENSAE Paris.\n",
    "\n",
    "Antoine Lelong, Louisa Camadini, Yseult Masson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a44447",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e19eda",
   "metadata": {},
   "source": [
    "Les commentaires postés sous les vidéos YouTube sont une source d'information pour les créateurs de contenu, ainsi que les \"likes\".  \n",
    "Ils permettent au vidéaste de déterminer si son travail a plu ou non à son audience. Cependant, les Youtubeurs n'ont pas nécessairement le temps de tous les lire. Il nous a donc semblé intéressant d'analyser ces commentaires informatiquement, plutôt que de les traiter un à un.\n",
    "\n",
    "Pour ce projet, nous nous sommes penchés sur la chaîne YouTube DirtyBiology, qui fait de la vulgarisation scientifique. Notre choix a été motivé par le fait que les commentaires sous de telles vidéos étaient à la fois nombreux (car la chaîne est relativement connue), constructifs (de par le contenu scientifique) et sans trop de fautes d'ortographes.  \n",
    "Cela nous permettait d'avoir des données exploitables pour l'analyse que nous voulions en faire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37cc698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290f977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des modules utiles\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda8cc61",
   "metadata": {},
   "source": [
    "# 1 - Webscraping, création et nettoyage de la base de données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945df210",
   "metadata": {},
   "source": [
    "## 1.1 - Webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1314369",
   "metadata": {},
   "source": [
    "Dans un premier temps, nous avons utilisé [l'API YouTube Data](https://developers.google.com/youtube/v3), qui nous permet de récupérer les 100 commentaires les plus \"pertinents\" d'une vidéo, sur jusqu'à 20 vidéos différentes, constituant ainsi une base de données de 2000 commentaires, ainsi que quelques données supplémentaires, comme le nombre de likes, le nom d'utilisateur...  \n",
    "Le script scraper.py va chercher ces données et les stocke dans le fichier comments.csv  \n",
    "Les API Google fonctionnent avec des clés d'identification confidentielles, qui n'apparaissent par conséquent pas dans le dépot github. Pour faire fonctionner le script correctement, il faut créer un fichier s'apppelant \".env\" et y placer la ligne suivante :  \n",
    "`APIKEY=\"identifiant_de_la_clé\"`  \n",
    "Sinon, le fichier comments.csv que nous avons constitué est, lui, disponible dans le dépot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4956dd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python scraper.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e0423b",
   "metadata": {},
   "source": [
    "## 1.2 - Nettoyage de la base de données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35e2a7b",
   "metadata": {},
   "source": [
    "Le script cleaning est prépare les commentaires aux applications des autres parties, en retirant les majuscules, sauts de lignes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d98aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python cleaning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf59d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"comments.csv\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf65751",
   "metadata": {},
   "source": [
    "# 2 - Analyse des commentaires\n",
    "## 2.1 - Analyse exploratoire quantitative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4248fcfc",
   "metadata": {},
   "source": [
    "Par simplicité, on remplace les identifiants de vidéo par des numéros dans l'ordre de publication (1 pour la plus ancienne, 20 pour la dernière vidéo sortie) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bd9e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = {data.videoId.unique()[i] : 20- i for i in range(len(data.videoId.unique()))}\n",
    "data['videoId']=data['videoId'].replace(to_replace=dico)\n",
    "data.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36870de3",
   "metadata": {},
   "source": [
    "Certaines données caractérisent la vidéo et non le commentaire, on les récupère dans une autre DataFrame. Elles sont égales sur une vidéo, donc égales à leur max sur ces groupes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bf5df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_video = data.groupby('videoId')[['viewCount', 'commentCount', 'videoLikeCount','videoDate']].max()\n",
    "info_video['likePerView'] = info_video['videoLikeCount']/info_video['viewCount']\n",
    "info_video['Engagement'] = info_video['commentCount']/info_video['viewCount']\n",
    "info_video.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68afe2bf",
   "metadata": {},
   "source": [
    "On crée une variable correspondant au nombre de mois entre la publication de la vidéo et celle de la dernière vidéo de la base de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dff357d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_mois = lambda date : 25 - (int(date[5:7])+12*int(date[3]))\n",
    "info_video['ancienneté'] = info_video.videoDate.apply(nbr_mois)\n",
    "info_video.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6405b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "info_video.plot(y='likePerView', ax=axs[0][0], color='r')\n",
    "info_video.plot(y='Engagement', ax=axs[0][0], color='b')\n",
    "axs[0][0].axis([0,20,0,1])\n",
    "axs[0][0].set_title(\"Part d'engagement du public\")\n",
    "\n",
    "info_video.plot(y='likePerView', ax=axs[1][0], color='r')\n",
    "info_video.plot(y='Engagement', ax=axs[1][0], color='b')\n",
    "axs[1][0].set_title(\"Comparaison des proportions de like et commentaires\")\n",
    "\n",
    "info_video.plot(y='Engagement', ax=axs[0][1], color='b')\n",
    "axs[0][1].set_title(\"Variation de l'engagement par commentaires\")\n",
    "\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = linregress(x=info_video.ancienneté, y=info_video.Engagement)\n",
    "\n",
    "info_video.plot.scatter(x='ancienneté', y='Engagement', ax=axs[1][1])\n",
    "axs[1][1].plot(info_video.ancienneté, slope*info_video.ancienneté + intercept, color='c')\n",
    "axs[1][1].set_title(\"Regression linéaire de l'engagement en commentaires sur l'ancienneté\")\n",
    "plt.text(x=0.5, y=0.006, s=f\"lope = {slope:.2e}\\nR-squared = {r_value**2:.2f} \\nP-value = {p_value:.3f}\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44a16ff",
   "metadata": {},
   "source": [
    "Comme on peut le voir, la part de viewers qui 'likent' et commentent reste stable autour de 9% et 0.4% respectivement, soit une minorité de la totalité des viewers.  \n",
    "On remarque une tendance à l'augmentation de la proportion de viewers qui commentent avec l'ancienneté de la vidéo, ce qui suggère que les personnes qui regardent la vidéo tard on plus tendance à commenter. L'interprétation de la régression linéaire donne que pour chaque mois qui passe, cette proportion augmente en moyenne de 0.001 (pour rappelle, elle varie aux alentours de 0.004 sur les observations).  \n",
    "La P-valeur à 0.006 montre que le coefficient de la courbe est significatif au seuil 1%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b89bc5f",
   "metadata": {},
   "source": [
    "## 2.2 - Thèmes majoritairement abordés dans les commentaires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185a8ee5",
   "metadata": {},
   "source": [
    "Imports nécessaires pour cette partie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d109aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac860fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('genesis')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20c25a4",
   "metadata": {},
   "source": [
    "### A - Tokenisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838c0a3c",
   "metadata": {},
   "source": [
    "On voit que l'on va s'intéresser ici à la colonne `'textClean'` qui a été nettoyée au préalable. Chaque ligne du dataframe représente un commentaire. L'ensemble de ces lignes, c'est-à-dire tous les commentaires, correspondent donc à notre texte d'étude. Il s'agit tout d'abord de décomposer le texte en unités lexicales, afin de pouvoir analyser les impressions laissées en commentaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cddd069",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \" \".join(data['textClean'])\n",
    "\n",
    "words = nltk.word_tokenize(content, language='french')\n",
    "#words[200:250]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6fba8e",
   "metadata": {},
   "source": [
    "La texte a bien été décomposé en 'tokens', mais ce ne sont pas tous des mots : certains peuvent être des signes de ponctuation, des smileys... \n",
    "La méthode `isalpha()` renvoie \"True\" si tous les caractères de la chaîne sont des alphabets, on l'utilise pour ne garder que les 'tokens' qui sont des mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfef0a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word for word in words if word.isalpha()]\n",
    "#words[200:250]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98f09d9",
   "metadata": {},
   "source": [
    "Maintenant, certains mots comme les déterminants, pronoms, sont répétitifs et inutiles à l'analyse du texte. On supprime donc ce qu'on appelle les 'stopwords' :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07242b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('french'))\n",
    "\n",
    "words = [w for w in words if not w in stop_words]\n",
    "print(words[200:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41df9b35",
   "metadata": {},
   "source": [
    "### B - Création de WordClouds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccde4534",
   "metadata": {},
   "source": [
    "Ils permettent de synthétiser les mots et expressions qui reviennent le plus couramment dans les commentaires, et l'on voit qu'ils sont plutôt positifs pour la chaine DirtyBiology !\n",
    "Les images suivantes sont disponibles dans l'onglet [graphes](https://github.com/taucmar/projet-python-2a/tree/main/graphs) de notre dépôt GitHub, sous les noms `wordcloud1.png` `logo_youtube.png` `logo_dirty_bio.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d5c3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cb0b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a wordcloud\n",
    "wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(text)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00195c18",
   "metadata": {},
   "source": [
    "On a ici généré un premier nuage de points classique, composé de 100 mots qui semblent positifs dès le premier coup d'œil : vidéo, travail, merci, incroyable , bravo, intéressant...  \n",
    "On customise ce nuage de mots en l'intégrant au logo YouTube :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6b41f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array(Image.open(\"mask.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b790a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a word cloud image\n",
    "wc = WordCloud(background_color=\"white\", max_words=90, mask=mask,\n",
    "               stopwords=stop_words, contour_width=3, contour_color='firebrick')\n",
    "\n",
    "# Generate a wordcloud\n",
    "wc.generate(text)\n",
    "\n",
    "# Store to file\n",
    "wc.to_file(\"./graphs/logo_youtube.png\")\n",
    "\n",
    "# Show\n",
    "plt.figure(figsize=[10,8])\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10f940c",
   "metadata": {},
   "source": [
    "Mieux encore, on peut utiliser le logo de DirtyBiology, en retravaillant des images trouvées sur [Internet](https://www.pinterest.fr/pin/148689225175699166/). L'image qui suit a été produite de la même manière."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca8b632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"./graphs/logo_dirty_bio.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7bd204",
   "metadata": {},
   "source": [
    "## 2.3 - Polarisation des commentaires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b7d0c8",
   "metadata": {},
   "source": [
    "### A - Calcul de polarités"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b62d3c",
   "metadata": {},
   "source": [
    "Le module TextBlob est un module python de NLP utilisé pour l'analyse de sentiments et qui permet, entre autres, de calculer la polarité d'un texte. Celle-ci est définie par un nombre entre -1 et 1, et détermine le degré de satisfaction ou d'insatisfaction qui se dégage du texte. Plus la polaritée est proche de 1, plus le texte dégage un sentiment positif, et vice-versa.\n",
    "\n",
    "Nous avons calculé la polarité de chaque commentaire de deux façons. Les fonctions permettant de faire ces calculs se trouvent dans le fichier polaritation_utiles. Nous avons d'une part appliqué directement la fonction du module TextBlob qui nous intéresse au commentaire. D'autre part, nous avons découpé chaque commentaire en phrases, avant d'appliquer à chacune de celles-ci la fonction qui renvoie leur polarisation, puis d'en faire la moyenne sur toutes les phrases du commentaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd011f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polarisation_utiles as pu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85c54bc",
   "metadata": {},
   "source": [
    "Nous avons ensuite ajouté 2 nouvelles colonnes à la base de données:\n",
    "\n",
    "   - Polarity : polarité de chaque commentaire, calculée sur le commentaire entier directement\n",
    "    \n",
    "   - sentencesPolarity : polarité de chaque commentaire, calculée en prenant la moyenne des polarités sur chaque phrase que comporte le commentaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a8013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Polarity\"] = data.loc[:,['textClean']].apply(pu.blober)\n",
    "data[\"sentencesPolarity\"] = data.loc[:,['textClean']].apply(pu.polarisation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b451cd7",
   "metadata": {},
   "source": [
    "Création d'une colonne de numéros des vidéos (ici ou partie 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e33b46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DBY'] = data.loc[:,['videoTitle']].apply(np.vectorize(lambda string : string[-7:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58edf163",
   "metadata": {},
   "source": [
    "### B - Analyse des polarités"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36311841",
   "metadata": {},
   "source": [
    "**Analyse d'une vidéo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea284a9",
   "metadata": {},
   "source": [
    "Dans un premier temps, on s'intéresse à la répartition des polarités pour une vidéo, ici la vidéo *\"Comment ces champis nous ont façonnés - DBY #76\"*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e41599",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['DBY'] == \"DBY #76\", ['Polarity', 'sentencesPolarity']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e013c78d",
   "metadata": {},
   "source": [
    "On voit que pour les deux types de polarité, il y a très peu de valeurs négatives. Cela implique que les commentaires de cette vidéo sont pour la plupart perçus comme positifs.\n",
    "Les écarts type sont de 0.29 et 0.26, ce qui est assez élevé pour des valeurs de polarités allant entre -0.2 (-0.1 pour \"sentencesPolarity\") et 1. Ainsi, les commentaires de cette vidéo dégagent plusieurs degrés de satisfaction, allant de neutre à très satisfait. La moitié d'entre eux sont relativement satisfaits, et ont une polarité se trouvant entre 0.15 et 0.50 (0.12 et 0.45 pour sentencesPolarity).\n",
    "\n",
    "Cela se perçoit bien sur les histogrammes ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea69d99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "data.loc[data['DBY'] == \"DBY #76\", 'Polarity'].plot.density(ax = axs[0])\n",
    "data.loc[data['DBY'] == \"DBY #76\", 'Polarity'].plot.hist(bins=20, density=True, ax = axs[0])\n",
    "\n",
    "axs[0].set_xlabel(\"Polarité calculée sur le commentaire entier\")\n",
    "axs[0].set_ylabel(\"Nombre de commentaires (renormalisé)\")\n",
    "axs[0].set_title(\"Répartition des polarités des commentaires sous la vidéo DBY #76\")\n",
    "\n",
    "data.loc[data['DBY'] == \"DBY #76\", 'sentencesPolarity'].plot.density(ax=axs[1])\n",
    "data.loc[data['DBY'] == \"DBY #76\", 'sentencesPolarity'].plot.hist(bins=20, density=True, ax=axs[1])\n",
    "\n",
    "axs[1].set_xlabel(\"Polarité calculée sur les phrases du commentaire prises une à une\")\n",
    "axs[1].set_ylabel(\"Nombre de commentaires (renormalisé)\")\n",
    "axs[1].set_title(\"Répartition des polarités des commentaires sous la vidéo DBY #76\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cfe22f",
   "metadata": {},
   "source": [
    "**Relation entre le nombre de likes d'un commentaire et sa polarité**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac901632",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.sort_values(\"Polarity\").set_index(\"Polarity\")[\"commentLikeCount\"]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 10))\n",
    "\n",
    "for i, ax in enumerate(np.array(axs).flatten()):\n",
    "    plot_data = data2.iloc[500*i:500*(i+1)]\n",
    "    plot_data.plot.density(ax=ax)\n",
    "    plot_data.plot.hist(bins=[0]+[200 + 50*i for i in range(100)], density=True, ax=ax)\n",
    "    ax.set_xlabel(\"Nombre de likes reçus par le commentaire\")\n",
    "    ax.set_ylabel(\"Nombre de commentaires (renormalisé)\")\n",
    "    ax.set_title(\"Répartition du nombre de likes reçus par les commentaires renvoyant un sentiment \" + [\"négatif ou neutre\", \"légèrement positif\", \"positif\", \"très positif\"][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670e82b9",
   "metadata": {},
   "source": [
    "Sur chacun des graphiques, la première barre représente les commentaires ayant reçu moins de 200 likes. On considère qu'un commentaire a \"percé\" lorsqu'il a reçu plus de 200 likes. Il semble que les commentaires les moins positifs (ce qui ont la polarité la plus faible) sont ceux qui ont le plus de chance d'avoir du succès. Cela pourrait être dû au fait que les commentaires émettant un avis, qui sont ceux qui reçoivent le plus de likes, sont plutôt neutres, contrairement à ceux qui indiquent que la vidéo a plu, qui dégagent un sentiment positif."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc851b2e",
   "metadata": {},
   "source": [
    "**Comparaison des vidéos entre elles**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a9c0fc",
   "metadata": {},
   "source": [
    "Nous avons ensuite fait la moyenne des polarités sur les 100 commentaires de chaque vidéo, ce qui nous permet de comparer les vidéos entre elles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26de99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapol = data.groupby(['DBY']).mean().sort_values('Polarity', ascending = False)\n",
    "datapol.loc[:, ['videoLikeCount', 'Polarity', 'sentencesPolarity']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f33c1a",
   "metadata": {},
   "source": [
    "Nous avons cherché à savoir si les résultats de polarisation restaient cohérents entre les deux méthodes utilisées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d50609a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datapol.loc[:,['Polarity','sentencesPolarity']].plot(kind = 'barh', figsize = (11, 7), color = ['lightblue', 'green'], title = 'Comparaison entre polarité sur les commentaires entiers et polarité sur les phrases des commentaires', xlabel = 'Episode de DirtyBiology')\n",
    "plt.legend(labels = ['Polarité : Commentaires entiers', 'Polarité : Phrases prises une à une'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab1e885",
   "metadata": {},
   "source": [
    "L'ordre des vidéos change un peu selon la définition que l'on utilise pour la polarité, mais les deux définitions semblent tout de même corrélées (globalement, la polarité prise sur chaque phrase augmente avec celle prise sur le commentaire entier).\n",
    "\n",
    "Dans la suite, on garde la polarité sur le commentaire entier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a790b82",
   "metadata": {},
   "source": [
    "La polarité est un témoin du succès qu'a eu une vidéo. On cherche à présent à la comparer à un autre marqueur de ce succès, à savoir le ratio de \"likes\" qu'à reçu une vidéo par rapport à son nombre de vues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4055df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapol['likeRatio'] = datapol.loc[:,'videoLikeCount'].divide(datapol.loc[:,'viewCount'])\n",
    "datapol.plot(kind = 'scatter', x = 'Polarity', y = 'likeRatio',figsize = (6, 5), marker = 'd', xlabel = 'Polarité', ylabel = 'Ratio de \\\"likes\\\" par rapport au nombre de vues', title = 'Corrélation entre la polarité et le nombre de \\\"likes\\\" d\\'une vidéo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e50f81",
   "metadata": {},
   "source": [
    "Il semble ne pas y avoir de corrélation entre ces deux marqueurs. Cela peut être dû au fait que la polarisation ne soit pas très précise, ou que les personnes qui commentent les vidéos n'aient pas le même profil que ceux qui se contentent de \"liker\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d3a6a3",
   "metadata": {},
   "source": [
    "## 2.4 - Analyse en composantes principales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c5a2b2",
   "metadata": {},
   "source": [
    "Dans cette partie, nous utilisons la bibliothèque [Sentence Transformer](https://github.com/UKPLab/sentence-transformers) pour transformer les phrases en vecteurs réels. Cela nous permet ensuite de faire une ACP, pour visualiser les différences entre les commentaires, et étudier les plus extrêmes, puisque l'ACP conserve un maximum de variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c22ee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608157fa",
   "metadata": {},
   "source": [
    "### A - Préparation de l'encoding\n",
    "1. On récupère les commentaires\n",
    "2. On isole le texte du reste de la base de données\n",
    "3. Dans la liste *font*, on fait correspondre à chaque indice de commentaire le numéro de la vidéo associée (pour faire des catégories dans l'ACP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea38a770",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = SentenceTransformer(\"xlm-r-bert-base-nli-stsb-mean-tokens\")\n",
    "data = pd.read_csv(\"./comments.csv\")\n",
    "\n",
    "comments = data[['textClean', 'videoId']]\n",
    "\n",
    "text = comments[\"textClean\"].values.tolist()\n",
    "\n",
    "dico_font_video = {}\n",
    "\n",
    "for i, videoid in enumerate(comments.videoId.unique()):\n",
    "    dico_font_video[videoid] = i\n",
    "\n",
    "font = [dico_font_video[videoid] for videoid in comments.videoId]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b25e77",
   "metadata": {},
   "source": [
    "### B -  Encoding et ACP\n",
    "\n",
    "On peut ensuite encoder le texte, ce qui les transforme en vecteurs de $\\mathbb{R}^{768}$, qu'on projette après dans $\\mathbb{R}^{2}$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c378061",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = st.encode(text)\n",
    "pca = PCA(2).fit_transform(embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b5f95c",
   "metadata": {},
   "source": [
    "### C - Clustering\n",
    "Pour une première visualisation, on réunit les commentaires par clusters (dans  $\\mathbb{R}^{768}$), et on utilise ces catégories lorsqu'on affiche sur l'ACP dans $\\mathbb{R}^{2}$. On récupère aussi les commentaires les plus proches des centroïdes afin d'avoir des commentaires \"représentants\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f310e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(5, n_init=80, max_iter=2000).fit(embs)\n",
    "\n",
    "center_indices = [\n",
    "    int(np.argmin([np.sum((x-centroid)**2) for x in embs]))\n",
    "    for centroid in kmeans.cluster_centers_]\n",
    "\n",
    "commentaires_representants = [comments.textClean[i] for i in center_indices]\n",
    "representants = ''\n",
    "for i, comment in enumerate(commentaires_representants):\n",
    "    representants += f'{i}:{comment} \\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafc962b",
   "metadata": {},
   "source": [
    "En préparation de l'affichage de cette partie et de la suivante, on stocke toutes les informations constituées jusque là dans une DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dfa025",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.array([pca[:, 0], pca[:, 1], font, kmeans.labels_]).transpose(),\n",
    "                    columns=['x', 'y', 'video#', 'label'])\n",
    "data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e523eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.scatterplot(data=data,\n",
    "                x='x',\n",
    "                y='y',\n",
    "                hue='label',\n",
    "                style='label',\n",
    "                s=30,\n",
    "                hue_norm=(0,6),\n",
    "                alpha=.8,\n",
    "                palette='hsv',\n",
    "                legend='full')\n",
    "# Mise en avant des centroides\n",
    "sns.scatterplot(x=[pca[i, 0] for i in center_indices], \n",
    "                y=[pca[i, 1] for i in center_indices],\n",
    "                style=[i for i in range(len(center_indices))],\n",
    "                s=100,\n",
    "                legend=False)\n",
    "plt.title(\"ACP des commentaires + clustering\")\n",
    "plt.show()\n",
    "print(representants)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68187544",
   "metadata": {},
   "source": [
    "Les commentaires centroides sont tous positifs.  \n",
    "Cela qui suggère que ce qui éloigne les différents clusters les uns des autres ne réside pas dans la positivité ou négativité du commentaire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e3ab5b",
   "metadata": {},
   "source": [
    "### D - Affichage par vidéo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e2989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.scatterplot(data=data,\n",
    "                x='x',\n",
    "                y='y',\n",
    "                hue='video#',\n",
    "                hue_norm=(0, 23),\n",
    "                s=50,\n",
    "                palette='hsv',\n",
    "                alpha=.5,\n",
    "                legend='full')\n",
    "plt.title(\"ACP des commentaires par video\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e55c6fc",
   "metadata": {},
   "source": [
    "Les commentaires de chaque vidéo ne semblent pas former de cluster particuliers dans l'ACP, on peut donc en déduire qu'aucune vidéo n'a suggéré de réaction particulièrement différente des autres, ou bien si des clusters sont cachés dans les dimensions perdues de la projection, c'est qu'ils ont des variances plus faibles que les différences observées dans l'ACP.  \n",
    "Pour vérfier encore ces similarités, on affiche simultannément l'ACP pour chaque nuage de point plutôt que de les superposer.\n",
    "Afin de pouvoir les comparer visuellement facilement, on entoure les nuages de points par l'enveloppe convexe du nuage total :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dd9f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "hull = ConvexHull(pca)\n",
    "\n",
    "fig, axs = plt.subplots(4, 5, figsize=(14, 10))\n",
    "for i, ax in enumerate(np.array(axs).flatten()):\n",
    "    sns.scatterplot(x=[pca[j, 0] for j in range(len(font)) if font[j] == i],\n",
    "                    y=[pca[j, 1] for j in range(len(font)) if font[j] == i],\n",
    "                    s=50,\n",
    "                    ax=ax,\n",
    "                    alpha=0.4)\n",
    "    for simplex in hull.simplices:\n",
    "            ax.plot(pca[simplex, 0], pca[simplex, 1], 'c')\n",
    "    ax.set_title(f'Video {i+1}', fontsize=10)\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63db7c0d",
   "metadata": {},
   "source": [
    "Les nuages de points semblent se déplacer de gauche à droite principalement, mais les variations ne sont pas énormes. Concrètement, les vidéos suscitent des réations similaires.  \n",
    "### E - À la frontière de l'ACP\n",
    "Les axes de l'ACP ne sont pas porteurs d'un sens clairement identifiable étant donnée la nature de la transformation des commentaires en vecteurs. On peut essayer de leur donner un sens en regardant les valeurs extrêmes de l'ACP et determiner ce qui éloigne les commentaire les plus éloignés d'un point de vue sémantique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608c0b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "for simplex in hull.simplices:\n",
    "    plt.plot(pca[simplex, 0], pca[simplex, 1], 'c')\n",
    "bound = np.array([pca[i] for i in hull.vertices])\n",
    "plt.scatter(x=bound[:, 0], y=bound[:, 1], color='r')\n",
    "for name, vect in zip(range(len(bound)), bound):\n",
    "    plt.annotate(name+1, vect)\n",
    "plt.title(\"Frontière de l'enveloppe convexe\")\n",
    "plt.show()\n",
    "print(*[f'{i+1} : ' + text[ind]+'\\n' for i, ind in enumerate(hull.vertices)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0241541",
   "metadata": {},
   "source": [
    "On remarque tout de suite que les commentaires de la région en haut à gauche (1, 2, 12, 13 et 14) partagent tous le même mot : \"merci\" et saluent la qualité et l'intérêt qu'ils ont pour la vidéo ('passionnant', 'enrichissant', 'intéressant', 'beau travail', 'travail de qualité'). Les commentaires du bas sont également élogieux. Tandis que les commentaires de la région opposée intègrent du langage fleuri (6: 'bordel', 8: 'merde') et sont moins élogieux. Le commentaire le plus à droite semble venir d'un professeur voulant se renseigner.  \n",
    "On peut donc supposer que plus on se déplace vers la partie gauche de l'espace, plus les commentaires sont élogieux, et les remerciements nombreux."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
